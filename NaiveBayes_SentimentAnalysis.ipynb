{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with MLlib\n",
    "__Author : Erica Lee__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from math import exp\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing**\n",
    "Data set: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "- Method : local\n",
    "- 25,000 highly polar movie reviews for training, and 25,000 for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training, positive documetns:  12500\n",
      "Total number of training, negative documetns:  12500\n",
      "Total number of testing, positive documetns:  12500\n",
      "Total number of testing, negative documetns:  12500\n"
     ]
    }
   ],
   "source": [
    "def parseline(line, label):\n",
    "    rgx = re.compile(\"([\\w][\\w']*\\w)\")\n",
    "    words = rgx.findall(line.lower().replace(\"<br\",\"\").replace(\"</br\",\"\"))\n",
    "    return {\"text\": words, \"label\": label}\n",
    "\n",
    "def parse_pos(line):\n",
    "    return parseline(line,1)\n",
    "\n",
    "def parse_neg(line):\n",
    "    return parseline(line,-1)\n",
    "\n",
    "# From local\n",
    "pos_train = sc.textFile(\"../aclImdb/train_pos.txt\").map(parse_pos)\n",
    "neg_train = sc.textFile(\"../aclImdb/train_neg.txt\").map(parse_neg)\n",
    "pos_test = sc.textFile(\"../aclImdb/test_pos.txt\").map(parse_pos)\n",
    "neg_test = sc.textFile(\"../aclImdb/test_neg.txt\").map(parse_neg)\n",
    "\n",
    "# pos_train = sc.textFile(s3files[0]).map(parse_pos)\n",
    "# neg_train = sc.textFile(s3files[1]).map(parse_neg)\n",
    "# pos_test = sc.textFile(s3files[2]).map(parse_pos)\n",
    "# neg_test = sc.textFile(s3files[3]).map(parse_neg)\n",
    "\n",
    "print \"Total number of training, positive documetns: \",pos_train.count()\n",
    "print \"Total number of training, negative documetns: \",neg_train.count()\n",
    "print \"Total number of testing, positive documetns: \",pos_test.count()\n",
    "print \"Total number of testing, negative documetns: \",neg_test.count()\n",
    "\n",
    "all_train = pos_train.union(neg_train)\n",
    "labels = all_train.map(lambda doc: doc[\"label\"], preservesPartitioning=True)\n",
    "\n",
    "all_test = pos_test.union(neg_test)\n",
    "\n",
    "tf = HashingTF().transform(all_train.map(lambda doc: doc[\"text\"], preservesPartitioning=True))\n",
    "tf.take(1)\n",
    "idf = IDF().fit(tf)\n",
    "\n",
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine using zip\n",
    "training = labels.zip(tfidf).map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "# Train and check\n",
    "model = NaiveBayes.train(training)\n",
    "trainlabel = labels.zip(model.predict(tfidf)).map(lambda x: {\"actual\": x[0], \"predicted\": x[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.94824\n"
     ]
    }
   ],
   "source": [
    "# trainlabel.collect()\n",
    "trainlabel = labels.zip(model.predict(tfidf)).map(lambda x: (x[0], x[1]))\n",
    "trainaccuracy = trainlabel.filter(lambda (x,v): x == v).count()/float(all_train.count())\n",
    "print \"Training Accuracy: \", trainaccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_test = all_test.map(lambda doc: doc[\"label\"], preservesPartitioning=True)\n",
    "tf_test = HashingTF().transform(all_test.map(lambda doc: doc[\"text\"], preservesPartitioning=True))\n",
    "idf_test = IDF().fit(tf_test)\n",
    "tfidf_test = idf.transform(tf_test)\n",
    "\n",
    "# predictions = model.predict(tfidf_test).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy:  0.7706\n"
     ]
    }
   ],
   "source": [
    "testlabel = labels_test.zip(model.predict(tfidf_test)).map(lambda x: (x[0], x[1]))\n",
    "accuracy = testlabel.filter(lambda (x,v): x == v).count()/float(all_test.count())\n",
    "print \"Final Accuracy: \", accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Simple, Naive Bayes Classifier from Scratch in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training, positive documetns:  12500\n",
      "Total number of training, negative documetns:  12500\n",
      "Total number of testing, positive documetns:  12500\n",
      "Total number of testing, negative documetns:  12500\n"
     ]
    }
   ],
   "source": [
    "print \"Total number of training, positive documetns: \",pos_train.count()\n",
    "print \"Total number of training, negative documetns: \",neg_train.count()\n",
    "print \"Total number of testing, positive documetns: \",pos_test.count()\n",
    "print \"Total number of testing, negative documetns: \",neg_test.count()\n",
    "\n",
    "pos_n = pos_train.map(lambda x: (x['text'])).flatMap(lambda x:x).count()\n",
    "neg_n = neg_train.map(lambda x: (x['text'])).flatMap(lambda x:x).count()\n",
    "\n",
    "pos_n_test = float(pos_test.count())\n",
    "neg_n_test = float(neg_test.count())\n",
    "\n",
    "all_train = pos_train.union(neg_train)\n",
    "all_test = pos_train.union(neg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of word count in 'positive' documents:  2826798\n",
      "Total number of word count in 'negative' documents:  2748845\n"
     ]
    }
   ],
   "source": [
    "counter = all_train.map(lambda x: (x['text'])).flatMap(lambda x:x).map(lambda x:(x,1)).reduceByKey(lambda x,y: x+y)\n",
    "poscount = pos_train.map(lambda x: (x['text'])).flatMap(lambda x:x).map(lambda x:(x,1)).reduceByKey(lambda x,y: x+y)\n",
    "negcount = neg_train.map(lambda x: (x['text'])).flatMap(lambda x:x).map(lambda x:(x,1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "print \"Total number of word count in 'positive' documents: \", pos_n\n",
    "print \"Total number of word count in 'negative' documents: \", neg_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posprob = poscount.map(lambda x: (x[0], (x[1],pos_n)))\n",
    "negprob = negcount.map(lambda x: (x[0], (x[1],neg_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltestcount = pos_n_test + neg_n_test\n",
    "truelabels = all_test.map(lambda x: x['label']).zipWithIndex().map(lambda x: (x[1], x[0]))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def indexdocs(docs):\n",
    "    return [(docs[0][i], docs[1]) for i in range(len(docs[0]))]\n",
    "\n",
    "testdocs = all_test.map(lambda x: x['text']).zipWithIndex().map(indexdocs).flatMap(lambda x:x)\n",
    "\n",
    "test_p = testdocs.join(posprob).map(lambda x:(x[1][0], np.log(x[1][1][0]/(float(x[1][1][1])))))\n",
    "test_n = testdocs.join(negprob).map(lambda x:(x[1][0], np.log(x[1][1][0]/(float(x[1][1][1])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_p2 = test_p.reduceByKey(lambda x,y: x+y)\n",
    "test_n2 = test_n.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.63524\n"
     ]
    }
   ],
   "source": [
    "def posneg(tup):\n",
    "    if tup[1][0] < tup[1][1]: pred = 1\n",
    "    else: pred = -1\n",
    "    return (tup[0],pred)\n",
    "\n",
    "test_pred = test_p2.join(test_n2).map(posneg)\n",
    "correct = test_pred.join(truelabels).map(lambda x:(x[1][0]*x[1][1] + 1)/2).collect()\n",
    "accuracy = sum(correct)/float(len(correct))\n",
    "print \"Accuracy: \", accuracy\n",
    "# test_pred.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
